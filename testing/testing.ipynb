{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zIk_V3_XsLRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDKP2nJZfqpv"
      },
      "outputs": [],
      "source": [
        "# 1. Install dependencies (Colab cell)\n",
        "!pip install langchain langchain-community sentence_transformers faiss-cpu ipywidgets pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Imports\n",
        "import pandas as pd\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.llms import HuggingFaceHub\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output"
      ],
      "metadata": {
        "id": "IIRlgEMdf1DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Hugging Face API Token (REQUIRED for HuggingFaceHub LLMs)\n",
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
      ],
      "metadata": {
        "id": "7n6P07UWf1Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. CSV Upload and Preprocessing\n",
        "import io\n",
        "upload = widgets.FileUpload(accept='.csv', multiple=False)\n",
        "display(upload)\n",
        "\n",
        "def get_dataframe_from_upload(upload_widget):\n",
        "    if not upload_widget.value:\n",
        "        return None\n",
        "    file_info = next(iter(upload_widget.value.values()))\n",
        "    content = io.BytesIO(file_info['content'])\n",
        "    try:\n",
        "        df = pd.read_csv(content)\n",
        "    except Exception:\n",
        "        content.seek(0)\n",
        "        df = pd.read_csv(content, delimiter=';')\n",
        "    return df\n",
        "\n",
        "# Wait for upload\n",
        "import time\n",
        "while not upload.value:\n",
        "    time.sleep(1)\n",
        "df = get_dataframe_from_upload(upload)\n",
        "print(\"CSV loaded. Shape:\", df.shape)\n",
        "display(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "0f2a6c1045fb470f940051c7a296623a"
          ]
        },
        "id": "bJNFDQmqf093",
        "outputId": "cbb42290-cb34-4c77-8a3c-a93f78a0772a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f2a6c1045fb470f940051c7a296623a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FileUpload(value={}, accept='.csv', description='Upload')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-19c05460c206>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataframe_from_upload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CSV loaded. Shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Convert CSV to Documents\n",
        "def df_to_documents(df):\n",
        "    docs = []\n",
        "    for idx, row in df.iterrows():\n",
        "        text = \"; \".join([f\"{col}: {row[col]}\" for col in df.columns])\n",
        "        docs.append(text)\n",
        "    return docs\n",
        "\n",
        "documents = df_to_documents(df)"
      ],
      "metadata": {
        "id": "T5xf_pJNf07B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Chunking (optional, for very wide/long rows)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = []\n",
        "for doc in documents:\n",
        "    docs.extend(text_splitter.split_text(doc))"
      ],
      "metadata": {
        "id": "zOTULpyYf04Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Embedding and Vector Store\n",
        "embed_model = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
        "vectorstore = FAISS.from_texts(docs, embedding=embed_model)"
      ],
      "metadata": {
        "id": "htkbG3kvf01y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. LLM Setup (Hugging Face public chat LLM)\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",  # You may use mistralai/Mistral-7B-Instruct-v0.2 or meta-llama/Meta-Llama-3-8B-Instruct\n",
        "    model_kwargs={\"temperature\": 0.2, \"max_new_tokens\": 512}\n",
        ")"
      ],
      "metadata": {
        "id": "443WCHktf0y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Prompt Template for Retrieval-Augmented Generation\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "You are a data analyst. Use the following extracted data from a CSV to answer the user's question.\n",
        "If the answer requires comparison or aggregation, show your reasoning.\n",
        "If the answer is not in the data, say \"Not found in data.\"\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {input}\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "MPyimPgnf0wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Retrieval Chain\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
        "rag_chain = create_retrieval_chain(retriever, llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "HZNw00dUf0td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. ipywidgets Chat Interface\n",
        "chat_history = []\n",
        "\n",
        "input_box = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Ask a question about your CSV...',\n",
        "    description='Query:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='80%')\n",
        ")\n",
        "output_area = widgets.Output()\n",
        "send_button = widgets.Button(description=\"Send\", button_style='primary')\n",
        "\n",
        "def on_send_clicked(b):\n",
        "    query = input_box.value\n",
        "    input_box.value = ''\n",
        "    with output_area:\n",
        "        print(f\"\\nUser: {query}\")\n",
        "    # Run RAG chain\n",
        "    result = rag_chain.invoke({\"input\": query})\n",
        "    answer = result['answer'] if 'answer' in result else result\n",
        "    with output_area:\n",
        "        print(f\"Bot: {answer}\")\n",
        "\n",
        "send_button.on_click(on_send_clicked)\n",
        "\n",
        "chat_ui = widgets.VBox([input_box, send_button, output_area])\n",
        "display(chat_ui)"
      ],
      "metadata": {
        "id": "rqJxtU8Hf0q2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}